<h1>Data Processing Using Spark</h1>

<h2>Description</h2>
Perform ETL (Specifical data transformation and integration) on two raw datasets. The transformations include adding, renaming and dropping unnecessary columns as well as joining dataframes. Write the results into a HIVE warehouse and an HDFS file system.
<br />


<h2>Languages and Utilities Used</h2>

- <b>PySpark</b> 
- <b>HIVE Warehouse</b>

<h2>Environments Used </h2>

- <b>Jupyter Notebooks</b> 


