<h1>Data Processing Using Spark</h1>

<h2>Description</h2>
Perform ETL (Specifical data transformation and integration) on two raw datasets. The transformations include adding, renaming and dropping unnecessary columns as well as joining dataframes. Write the results into a HIVE warehouse and an HDFS file system.
<br />


<h2>Languages and Utilities Used</h2>

- <b>PySpark</b> 
- <b>HIVE Warehouse</b>

<h2>Environments Used </h2>

- <b>Jupyter Notebooks</b> 

<h2>Project Snapshot</h2>

<p align="center">
Launch the utility: <br/>
<img src="https://i.imgur.com/62TgaWL.png" height="80%" width="80%" alt="Disk Sanitization Steps"/>
<br /> </p>

